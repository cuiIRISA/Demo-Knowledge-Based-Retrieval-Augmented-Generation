{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8b01c33-3585-4cdd-bf1b-30bd0fa7b9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"jumpstart-dft-hf-text2text-flan-t5-xxl\"\n",
    "kendra_index_id = \"ebd13115-d4c2-4371-bfc2-***********\"\n",
    "region = \"eu-west-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a1e809fa-786e-47f4-adb3-cf5719a4a431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "#Put the correct endpoint name \n",
    "endpoint_name = endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34a28ddb-a897-436c-9398-ab8c4f477921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template_without_context = \"\"\"\n",
    "\"\\nThe following is a friendly conversation between a human and an AI.\\nThe AI is talkative and provides lots of specific details from its context.\\n\n",
    "If the AI does not know the answer to a question, it truthfully says it\\ndoes not know.\\n\n",
    "\\nInstruction: Based on the above documents, provide a detailed answer for, What's SageMaker? Solution:\\n\"\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_context = \"\"\"\n",
    "\"\\nThe following is a friendly conversation between a human and an AI.\\nThe AI is talkative and provides lots of specific details from its context.\\n\n",
    "If the AI does not know the answer to a question, it truthfully says it\\ndoes not know.\\n\n",
    "Document Title: Getting started with AWS Inferentia development - Amazon Elastic Compute Cloud\\n\n",
    "Document Excerpt: \\nGetting started There are a variety of ways that you can get started. Use Amazon SageMaker, a fully-managed service that is the easiest way to get started with machine learning models. For more information, see Compile and deploy a TensorFlow model on Inf1 instances on github. Launch an Inf1 instance using the Deep Learning AMI. For more information, see AWS Inferentia with DLAMI in the AWS Deep Learning AMI Developer Guide.\\n\\n\\n\n",
    "Document Title: Getting started with AWS Inferentia development - Amazon Elastic Compute Cloud\\n\n",
    "Document Excerpt: \\nUse Amazon SageMaker, a fully-managed service that is the easiest way to get started with\\n\\n\\n\n",
    "Document Title: Best practices for EC2 Spot - Amazon Elastic Compute Cloud\\n\n",
    "Document Excerpt: \\nworkloads: Amazon EMR, Amazon ECS, AWS Batch, Amazon EKS, Amazon SageMaker, AWS Elastic Beanstalk, and Amazon GameLift. To learn more about Spot best practices with these services\\n\n",
    "\\nInstruction: Based on the above documents, provide a detailed answer for, What's SageMaker? Answer \\\"don't know\\\" if not present in the document. Solution:\\n\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"max_length\": 500,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"num_beams\": 1,\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"temperature\": 0.000001\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa80d0-bf67-437b-a171-d15f94ec42d1",
   "metadata": {},
   "source": [
    "### LLM answers the question wrongly without any input context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6540bb6d-196f-4736-ac3f-45dde29e061a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"generated_texts\": [\"SageMaker is a software tool for creating a sage file.\"]}'\n"
     ]
    }
   ],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"text_inputs\": prompt_template_without_context, **parameters}),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61300c7d-d395-49f5-a81b-f8594ef70d31",
   "metadata": {},
   "source": [
    "### LLM answers the question correctly with input context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3cbde57e-e438-46c6-9eef-1caf15a6d5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"generated_texts\": [\"Amazon SageMaker, a fully-managed service that is the easiest way to get started with machine learning models.\"]}'\n"
     ]
    }
   ],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"text_inputs\": prompt_template_context, **parameters}),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d82ade-5397-43cb-b273-921e87537ce4",
   "metadata": {},
   "source": [
    "### Now we can fetch the correct context from Amazon Kendra, then put into LLM as the context information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f0b1a0d-97af-4479-b3fb-17be440a579a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_texts': ['Amazon SageMaker is a fully-managed service that is the easiest way to get started with machine learning models.']}\n",
      "{'query': \"What's SageMaker?\", 'result': 'Amazon SageMaker is a fully-managed service that is the easiest way to get started with machine learning models.', 'source_documents': [Document(page_content='Document Title: Getting started with AWS Inferentia development - Amazon Elastic Compute Cloud\\nDocument Excerpt: \\nGetting started There are a variety of ways that you can get started. Use Amazon SageMaker, a fully-managed service that is the easiest way to get started with machine learning models. For more information, see Compile and deploy a TensorFlow model on Inf1 instances on github. Launch an Inf1 instance using the Deep Learning AMI. For more information, see AWS Inferentia with DLAMI in the AWS Deep Learning AMI Developer Guide.\\n', metadata={'source': 'https://s3.eu-west-1.amazonaws.com/amazon-kendra-sample-docs-eu-west-1/documents/AWSEC2/latest/UserGuide/inf-getting-started.html', 'title': 'Getting started with AWS Inferentia development - Amazon Elastic Compute Cloud', 'excerpt': 'Getting started There are a variety of ways that you can get started. Use Amazon SageMaker, a fully-managed service that is the easiest way to get started with machine learning models. For more information, see Compile and deploy a TensorFlow model on Inf1 instances on github. Launch an Inf1 instance using the Deep Learning AMI. For more information, see AWS Inferentia with DLAMI in the AWS Deep Learning AMI Developer Guide.', 'type': 'ANSWER'}), Document(page_content='Document Title: Getting started with AWS Inferentia development - Amazon Elastic Compute Cloud\\nDocument Excerpt: \\nUse Amazon SageMaker, a fully-managed service that is the easiest way to get started with\\n', metadata={'source': 'https://s3.eu-west-1.amazonaws.com/amazon-kendra-sample-docs-eu-west-1/documents/AWSEC2/latest/UserGuide/inf-getting-started.html', 'title': 'Getting started with AWS Inferentia development - Amazon Elastic Compute Cloud', 'excerpt': 'Use Amazon SageMaker, a fully-managed service that is the easiest way to get started with', 'type': 'DOCUMENT'}), Document(page_content='Document Title: Best practices for EC2 Spot - Amazon Elastic Compute Cloud\\nDocument Excerpt: \\nworkloads: Amazon EMR, Amazon ECS, AWS Batch, Amazon EKS, Amazon SageMaker, AWS Elastic Beanstalk, and Amazon GameLift. To learn more about Spot best practices with these services\\n', metadata={'source': 'https://s3.eu-west-1.amazonaws.com/amazon-kendra-sample-docs-eu-west-1/documents/AWSEC2/latest/WindowsGuide/spot-best-practices.html', 'title': 'Best practices for EC2 Spot - Amazon Elastic Compute Cloud', 'excerpt': 'workloads: Amazon EMR, Amazon ECS, AWS Batch, Amazon EKS, Amazon SageMaker, AWS Elastic Beanstalk, and Amazon GameLift. To learn more about Spot best practices with these services', 'type': 'DOCUMENT'})]}\n"
     ]
    }
   ],
   "source": [
    "from aws_langchain.kendra_index_retriever import KendraIndexRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "import json\n",
    "\n",
    "class ContentHandler(ContentHandlerBase):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        parameters = {\n",
    "            \"max_length\": 500,\n",
    "            \"num_return_sequences\": 1,\n",
    "            \"num_beams\": 1,\n",
    "            \"no_repeat_ngram_size\": 3,\n",
    "            \"temperature\": 0.000001\n",
    "        }\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **parameters})\n",
    "        #print(input_str)\n",
    "        #input_str = json.dumps({\"text_inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        #return input_str\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        print(response_json)\n",
    "        return response_json['generated_texts'][0]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "llm=SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name,\n",
    "        region_name=region, \n",
    "        model_kwargs={\"temperature\":1e-10, \"max_length\": 500},\n",
    "        content_handler=content_handler\n",
    "    )\n",
    "\n",
    "retriever = KendraIndexRetriever(kendraindex=kendra_index_id,\n",
    "        awsregion=region,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it\n",
    "does not know.\n",
    "{context}\n",
    "Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" if not present in the document. Solution:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")\n",
    "result = qa(\"What's SageMaker?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbdf14-d2c6-4b5a-9b4c-27f65b7b2afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
